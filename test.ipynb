{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dr/anaconda3/envs/demo/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as  nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: Inputs device: cuda:0, Targets device: cuda:0\n",
      "Batch 1: Inputs device: cuda:0, Targets device: cuda:0\n",
      "Batch 2: Inputs device: cuda:0, Targets device: cuda:0\n",
      "Batch 3: Inputs device: cuda:0, Targets device: cuda:0\n",
      "Batch 4: Inputs device: cuda:0, Targets device: cuda:0\n",
      "Batch 5: Inputs device: cuda:0, Targets device: cuda:0\n",
      "Batch 6: Inputs device: cuda:0, Targets device: cuda:0\n",
      "Batch 7: Inputs device: cuda:0, Targets device: cuda:0\n",
      "Batch 8: Inputs device: cuda:0, Targets device: cuda:0\n",
      "Batch 9: Inputs device: cuda:0, Targets device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# 创建一些示例数据\n",
    "data = torch.randn(100, 10)  # 100 个样本，每个样本有 10 个特征\n",
    "labels = torch.randint(0, 2, (100,))  # 100 个标签，每个标签是 0 或 1\n",
    "\n",
    "# 创建 TensorDataset 和 DataLoader\n",
    "dataset = TensorDataset(data, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "# 设置设备为 CUDA（如果可用）\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 遍历 DataLoader 并将每个 batch 移动到 CUDA 设备\n",
    "for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "    inputs = inputs.to(device)  # 将输入数据移动到 CUDA 设备\n",
    "    targets = targets.to(device)  # 将标签移动到 CUDA 设备\n",
    "    print(f\"Batch {batch_idx}: Inputs device: {inputs.device}, Targets device: {targets.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=torch.randn(4,5)\n",
    "c=c[:,-1]\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5801)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "logits = torch.tensor([[1.2, -0.5, 0.8], [0.3, 1.1, -0.2]])  # 假设两个样本的预测分数向量\n",
    "targets = torch.tensor([0, 1])  # 对应的真实标签索引\n",
    "\n",
    "loss = F.cross_entropy(logits, targets)\n",
    "# 前向传播\n",
    "\n",
    "\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'I': 2,\n",
       "         ' ': 58,\n",
       "         'H': 1,\n",
       "         'A': 1,\n",
       "         'D': 1,\n",
       "         'a': 22,\n",
       "         'l': 10,\n",
       "         'w': 6,\n",
       "         'y': 2,\n",
       "         's': 12,\n",
       "         't': 19,\n",
       "         'h': 26,\n",
       "         'o': 21,\n",
       "         'u': 9,\n",
       "         'g': 11,\n",
       "         'J': 1,\n",
       "         'c': 4,\n",
       "         'k': 1,\n",
       "         'G': 1,\n",
       "         'i': 20,\n",
       "         'b': 3,\n",
       "         'r': 17,\n",
       "         'n': 12,\n",
       "         'e': 26,\n",
       "         'p': 5,\n",
       "         '-': 4,\n",
       "         'd': 9,\n",
       "         'f': 3,\n",
       "         'm': 4,\n",
       "         ',': 4,\n",
       "         'v': 3,\n",
       "         'R': 2,\n",
       "         '.': 2,\n",
       "         '(': 1,\n",
       "         'T': 1,\n",
       "         'F': 1,\n",
       "         ')': 1})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "text=\"I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no great surprise to me to hear that, in the height of his glory, he had dropped his painting, married a rich widow, and established himself in a villa on the Riviera. (Though I rather thought it would have been Rome or Florence.)\"\n",
    "# 统计字符频率\n",
    "counts = Counter(text)\n",
    "# 初始化BPE词汇表\n",
    "vocab = {char: i for i, char in enumerate(counts)}\n",
    "# 初始化BPE排名\n",
    "bpe_ranks = {v: k for k, v in vocab.items()}\n",
    "# 初始化缓存\n",
    "cache = {}\n",
    "        \n",
    "counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 5])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=torch.randn(3,2,5)\n",
    "c=c.flatten(0,1)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., -inf],\n",
      "        [0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "seq_len=2\n",
    "\n",
    "\n",
    "causal_mask = torch.triu(torch.full((seq_len, seq_len), float(\"-inf\")), diagonal=1)\n",
    "\n",
    "print(causal_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employee objects are:\n",
      "Employee(name='Satyam', emp_id='ksatyam858', age=21, city='Patna')\n",
      "Employee(name='Anurag', emp_id='au23', age=28, city='Delhi')\n",
      "Employee(name='Satyam', emp_id='ksatyam858', age=21, city='Patna')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "# A class for holding an employee's content\n",
    "@dataclass\n",
    "class Employee:\n",
    "    # Attributes Declaration\n",
    "    # using Type Hints\n",
    "    name: str\n",
    "    emp_id: str\n",
    "    age: int\n",
    "    city: str\n",
    "\n",
    "# Correctly initializing employee objects\n",
    "emp1 = Employee(\"Satyam\", \"ksatyam858\", 21, 'Patna')\n",
    "emp2 = Employee(\"Anurag\", \"au23\", 28, 'Delhi')\n",
    "emp3 = Employee(name=\"Satyam\", emp_id=\"ksatyam858\", age=21, city='Patna')\n",
    "\n",
    "print(\"Employee objects are:\")\n",
    "print(emp1)\n",
    "print(emp2)\n",
    "print(emp3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MultiScaleModule(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(MultiScaleModule, self).__init__()\n",
    "        self.conv_1x1_init = nn.Conv2d(in_channels, in_channels, kernel_size=1)\n",
    "        self.conv_7x7 = nn.Conv2d(in_channels, out_channels, kernel_size=7, padding=3)\n",
    "        self.conv_5x5 = nn.Conv2d(in_channels, out_channels, kernel_size=5, padding=2)\n",
    "        self.conv_3x3 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv_1x1_final = nn.Conv2d(out_channels * 3, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 原始输入\n",
    "        x_copy = x\n",
    "        # 1×1卷积\n",
    "        x = self.conv_1x1_init(x)\n",
    "        # 并行卷积，不同的卷积核+concat操作\n",
    "        print(self.conv_7x7(x).shape)\n",
    "        print(self.conv_5x5(x).shape)\n",
    "        print(self.conv_3x3(x).shape)\n",
    "        concatenated = torch.cat([self.conv_7x7(x), self.conv_5x5(x), self.conv_3x3(x)], dim=1)\n",
    "        # 1×1卷积\n",
    "        out = self.conv_1x1_final(concatenated)\n",
    "        # 残差连接\n",
    "        return out + x_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 24, 24])\n",
      "torch.Size([1, 10, 24, 24])\n",
      "torch.Size([1, 10, 24, 24])\n",
      "tensor([[[[ 8.5865e-01,  7.1786e-01,  9.9234e-01,  ...,  2.9483e-01,\n",
      "           -5.3494e-01,  1.0754e+00],\n",
      "          [-8.1317e-01,  1.1767e+00, -1.2442e+00,  ..., -6.3357e-01,\n",
      "            3.8048e-01,  3.8241e-01],\n",
      "          [ 1.2208e-01,  6.2397e-01, -5.5678e-01,  ..., -9.4688e-01,\n",
      "            5.3937e-01, -5.3684e-01],\n",
      "          ...,\n",
      "          [-3.1947e-01, -7.6455e-01, -1.5348e+00,  ..., -9.6370e-01,\n",
      "            8.5453e-01, -2.9116e+00],\n",
      "          [-6.9546e-01,  4.8907e-01, -1.3825e+00,  ...,  5.7192e-01,\n",
      "           -1.6440e-01, -6.3328e-01],\n",
      "          [-8.2243e-01,  2.1238e+00, -1.2568e+00,  ..., -2.2541e-01,\n",
      "            1.2372e-01, -1.0780e+00]],\n",
      "\n",
      "         [[-6.2135e-01, -5.1878e-01,  2.0989e-01,  ..., -1.8397e+00,\n",
      "            1.1681e+00, -6.1807e-01],\n",
      "          [ 1.4773e+00,  3.8341e-02,  1.5018e+00,  ..., -1.4747e+00,\n",
      "            1.3043e+00,  3.6366e-02],\n",
      "          [-1.3360e-01, -2.6706e-01,  4.8792e-01,  ..., -1.0883e+00,\n",
      "            1.8135e+00, -3.8581e-01],\n",
      "          ...,\n",
      "          [ 3.5774e-01,  4.5024e-01,  1.5632e+00,  ...,  8.5645e-01,\n",
      "           -3.2363e-04,  1.0583e+00],\n",
      "          [ 1.2154e+00,  3.0216e-01,  1.0209e+00,  ...,  1.1202e+00,\n",
      "           -2.3128e-01, -1.9430e-01],\n",
      "          [-8.8167e-01,  1.2999e+00,  1.1532e+00,  ...,  1.2296e+00,\n",
      "           -3.3127e-02,  1.4477e-01]],\n",
      "\n",
      "         [[-3.6524e-01,  1.1356e+00, -1.5530e-01,  ...,  4.7944e-01,\n",
      "            1.0681e+00,  2.5105e-01],\n",
      "          [-5.5825e-01, -2.4534e+00, -6.0812e-01,  ...,  8.7317e-01,\n",
      "           -4.7889e-01,  2.4034e-01],\n",
      "          [-1.0348e+00, -1.6661e+00,  8.4378e-01,  ..., -8.9045e-01,\n",
      "            8.9386e-01,  1.0269e+00],\n",
      "          ...,\n",
      "          [-1.7226e+00, -2.9802e+00,  9.8993e-01,  ...,  8.2883e-01,\n",
      "           -4.8655e-01,  8.8333e-01],\n",
      "          [-8.6369e-01, -1.6309e+00, -1.9303e+00,  ..., -1.7289e+00,\n",
      "            1.9692e-01, -6.0581e-01],\n",
      "          [-1.1859e+00, -1.4897e-01, -8.6568e-01,  ..., -1.0945e+00,\n",
      "           -6.1717e-01,  1.3576e+00]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.8881e-01,  5.1664e-01, -1.7839e+00,  ...,  1.2718e+00,\n",
      "           -1.1718e+00,  8.3714e-01],\n",
      "          [-7.0291e-02,  2.0756e+00,  1.5958e+00,  ..., -5.6026e-01,\n",
      "            2.4280e-01, -1.5048e+00],\n",
      "          [-8.7935e-01, -1.1066e+00, -1.1739e+00,  ..., -1.3471e+00,\n",
      "            1.8654e+00,  1.4597e-01],\n",
      "          ...,\n",
      "          [-3.0193e-01,  9.7780e-01, -3.1920e-01,  ...,  9.2323e-01,\n",
      "           -3.1876e-03,  5.2609e-01],\n",
      "          [-6.4084e-01,  3.3092e-02, -9.8496e-02,  ..., -3.7942e-01,\n",
      "           -9.1086e-03, -2.4569e-01],\n",
      "          [-3.4130e-01,  5.9790e-01,  4.4276e-01,  ..., -1.4675e+00,\n",
      "           -1.0769e+00, -1.2720e+00]],\n",
      "\n",
      "         [[ 1.8846e+00, -1.7973e+00,  6.9847e-01,  ..., -3.2457e-01,\n",
      "           -1.9044e-01, -2.5118e+00],\n",
      "          [-1.0670e+00, -1.3996e+00, -5.7876e-01,  ...,  4.2092e-01,\n",
      "           -2.0408e+00, -1.1231e+00],\n",
      "          [-7.3550e-01, -4.3231e-01, -3.8301e-01,  ...,  1.9315e+00,\n",
      "            2.8721e-01, -4.7570e-01],\n",
      "          ...,\n",
      "          [-1.4938e-01, -4.0258e-01,  5.8472e-01,  ...,  7.3125e-01,\n",
      "            1.4943e+00,  8.1745e-01],\n",
      "          [-8.0700e-01,  9.6168e-01, -7.0386e-01,  ..., -2.0109e+00,\n",
      "           -2.3995e+00,  1.8171e-01],\n",
      "          [ 3.4658e-01,  7.0727e-01,  1.6225e+00,  ...,  2.4585e+00,\n",
      "           -4.5759e-01,  1.6181e+00]],\n",
      "\n",
      "         [[ 5.6829e-02,  6.8389e-01, -1.6029e+00,  ...,  1.9074e-01,\n",
      "            4.6713e-01, -1.3025e+00],\n",
      "          [-6.8952e-01,  4.7721e-01,  2.2056e+00,  ..., -2.9114e+00,\n",
      "            8.2644e-02,  7.3359e-02],\n",
      "          [-6.8004e-01,  7.0358e-01, -3.4083e-01,  ...,  5.9957e-01,\n",
      "           -1.2813e+00, -6.6380e-01],\n",
      "          ...,\n",
      "          [-6.0313e-01, -2.9108e-01, -1.2806e+00,  ..., -1.5845e+00,\n",
      "           -6.4140e-01,  4.3630e-01],\n",
      "          [ 6.6159e-01,  3.5941e-01, -8.6455e-01,  ..., -5.6277e-01,\n",
      "            4.4456e-01, -7.7354e-01],\n",
      "          [-1.5795e+00, -5.8746e-01, -1.4982e+00,  ..., -1.0005e+00,\n",
      "           -3.7158e-01,  9.1782e-02]]]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "c=MultiScaleModule(10,10)\n",
    "i=torch.randn(1,10,24,24)\n",
    "print(c(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mlp(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size,dropout=0.2):\n",
    "        super(mlp, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "\n",
    "        self.layers=nn.Sequential(\n",
    "            nn.Linear(input_size, 4*hidden_size),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4*hidden_size, output_size),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=mlp(10,20,20)\n",
    "\n",
    "x=torch.randn(20,10)\n",
    "y=model(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
